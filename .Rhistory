library(broom)
library(ltm)
library(MASS)
wwines <- read.csv("winequality-white.csv", sep=";")
print("White wines")
str(wwines)
wwines$quality <- as.factor(case_when(wwines$quality <= 5 ~ "low",
wwines$quality > 5 ~ "high"))
wwines$quality <- factor(wwines$quality, levels = c("low","high"))
table(wwines$quality)
#compute on all features (without output variable which is at index 12)
cors <- cor(wwines[-12])
corrplot(cors, type = "upper",
tl.col = "black", tl.srt = 45)
h1 <- ggplot(wwines, aes(residual.sugar, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
h2 <- ggplot(wwines, aes(alcohol, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
h3 <- ggplot(wwines, aes(density, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
grid.arrange(h1,h2,h3, ncol=1)
wwines$density <- NULL
bicorrs <- sapply(wwines[,-11], function(x) round(biserial.cor(x,wwines$quality),2))
data.frame(bicorrs) %>% arrange(abs(bicorrs))
summary(wwines)
# melt the dataset
wwines.m <- melt(wwines, id.var = "quality")
# wrapped boxplots
ggplot(data = wwines.m, aes(x=variable, y=value)) +
geom_boxplot(aes(fill=quality)) +
facet_wrap( ~ variable, scales="free")
set.seed(42)
train_indices<- createDataPartition(wwines$quality,p=0.7,list=FALSE)
lr_fit <- glm(quality ~., data =  wwines[train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit)
# odds ratios
exp(cbind(OR = coef(lr_fit), confint(lr_fit)))
#here we use mlr3 package
#defining our task: classification on wines with quality as response variable and low quality as baseline
task_train = TaskClassif$new(id = "wines",  wwines[train_indices,], target = "quality", positive = "low")
#defining the learner which will perform the training procedure on our model
learner_train = lrn("classif.log_reg", predict_type = "prob")
#defining how we want to perform cross validation (setting number of folds to 5)
cv5 = rsmp("cv", folds = 5)
#we want to tweak the threshold of our classification: we analyze values from 0.3 to 0.6 with step 0.01
thresholds <- seq(0.3,0.6,0.01)
#collecting performances with different thresholds
accuracy <- list()
sensitivity <- list()
specificity <- list()
auroc <- list()
i <- 1
for (thresh in thresholds) {
res_cv = resample(task_train, learner_train, cv5, store_models = TRUE)
#combined prediction of all individual resampling iterations
prediction <- res_cv$prediction()
prediction$set_threshold(thresh)
#scores are combined as well from all individual resampling iterations
accuracy[i] <- prediction$score(measures = msr("classif.acc"), task = task_train)
sensitivity[i] <- prediction$score(measures = msr("classif.sensitivity"), task = task_train)
specificity[i] <- prediction$score(measures = msr("classif.specificity"), task = task_train)
auroc[i] <- prediction$score(measures = msr("classif.auc"), task = task_train)
i<-i+1
}
#collecting scores
measures <- data.frame(thresholds,
"accuracy" =unlist(accuracy),
"sensitivity" =unlist(sensitivity),
"specificity" = unlist(specificity),
"auroc" = unlist(auroc))
#finding optimal point: intersection
equivalent <- function(x, y, tol = 0.02) abs(x - y) < tol
intersection_indices <- which(equivalent(measures$sensitivity,measures$specificity))
melt_measures <- melt(measures, id.vars="thresholds")
ggplot(melt_measures, aes( x=thresholds, y=value, colour=variable, group=variable )) +
geom_line() +
geom_vline(xintercept = mean(thresholds[intersection_indices]),linetype = "dotted") +
geom_label(aes(x = 0.37, y = 0.5, label = "0.355"))
# define new task for test set
task_test = TaskClassif$new(id = "wines_test",  wwines[-train_indices,], target = "quality", positive = "low")
# train on train task
learner_train$train(task_train)
# predict on test task
pred <- learner_train$predict(task_test)
# set optimal threshold
pred$set_threshold(mean(thresholds[intersection_indices]))
# performance
cm <- list("confusion" = pred$confusion,
"accuracy" = pred$score(measures = msr("classif.acc")),
"sensitivity"=pred$score(measures = msr("classif.sensitivity")),
"specificity"=pred$score(measures = msr("classif.specificity")))
cm
a <- vif(lr_fit)
#b <- data.frame(a,colnames(wwines)[-12])  %>% mutate(sqrt = sqrt(a)) %>% filter(sqrt > 2)
sqrt(vif(lr_fit))>2 # residual.sugar, density, alcohol
library(leaps)
regfit.fwd=regsubsets(quality~.,data=wwines,method="forward", nvmax=13)
summary.fwd <- summary(regfit.fwd)
plot(summary.fwd$bic,xlab="Number of Variables",ylab="bic")
points(which.min(summary.fwd$bic),summary.fwd$bic[which.min(summary.fwd$bic)],pch=20,col="red")
plot(regfit.fwd,scale="bic")
grid(nx=11,ny=10,col="red",lty = "solid")
abline(h=10, col="yellow", lwd = 10)
text(10.5,9, "Optimal model", col="yellow",cex = 0.8)
lr_fit_res <- glm(quality ~ fixed.acidity+volatile.acidity+residual.sugar+free.sulfur.dioxide+sulphates+alcohol, data =  wwines[train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit_res)
# odds ratios
exp(cbind(OR = coef(lr_fit_res), confint(lr_fit_res)))
#unrestricted model performance
unrestr_probs <- predict(lr_fit,  wwines[-train_indices,], type="response")
unrestr_preds <- ifelse(unrestr_probs < 0.355,"low","high")
unrestr_cm <- confusionMatrix(factor(unrestr_preds,levels=c("high","low")),
wwines[-train_indices,]$quality,
positive = "low"
)
unrestr_performance <- list(unrestr_cm$overall[1], unrestr_cm$byClass[1], unrestr_cm$byClass[2])
#restricted model performance
restr_probs <- predict(lr_fit_res,  wwines[-train_indices,], type="response")
restr_preds <- ifelse(restr_probs < 0.355,"low","high")
restr_cm <- confusionMatrix(factor(restr_preds,levels=c("high","low")),                         wwines[-train_indices,]$quality,
positive = "low"
)
restr_performance <- list(restr_cm$overall[1], restr_cm$byClass[1], restr_cm$byClass[2])
data.frame("unrestr_performance" =unlist(unrestr_performance),"restr_performance" = unlist(restr_performance),
"improvement" = unlist(restr_performance)-unlist(unrestr_performance))
#see Cook's distance
influenceIndexPlot(lr_fit, id.n=10)  # 2782, 4481
#using dffits
df_fits<-dffits(lr_fit)
threshold<-(2*(11+1)/sqrt(3429-11-1))
which(abs(df_fits)>threshold) # 2782, 1956
outliers <- c(1956,2782,4481)
wwines[train_indices,]["outlier"] <- ifelse(rownames( wwines[train_indices,]) %in% outliers,0,1)
residualPlots(lr_fit, id = TRUE,  col = as.factor( wwines[train_indices,]$outlier))
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold)
#%>%  select(.rownames)
wwines[train_indices,]["outlier"] <- ifelse(rownames(wwines[train_indices,]) %in% outliers$.rownames,0,1)
residualPlots(lr_fit, id = TRUE, col = as.factor( wwines[train_indices,]$outlier), ask = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(reshape2)
library(mlr3learners)
library(pROC)
library(corrplot)
library(gridExtra)
library(GGally)
library(car)
library(broom)
library(ltm)
library(MASS)
wwines[train_indices,]$outlier<- NULL
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-outliers,]
outliers
wwines[train_indices,]$outlier<- NULL
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-outliers$.rownames,]
outliers$.rownames
wwines[train_indices,]$outlier<- NULL
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-unlist(outliers$.rownames),]
wwines[train_indices,]$outlier<- NULL
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][,-outliers$.rownames]
wwines[train_indices,]$outlier<- NULL
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-as.numeric(outliers$.rownames),]
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold)
%>%  select(.rownames)
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold) %>%
select(.rownames)
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold) %>%
select(".rownames")
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold) %>%
select(lr_fit$.rownames)
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold)
wwines[train_indices,]["outlier"] <- ifelse(rownames(wwines[train_indices,]) %in% outliers$.rownames,0,1)
residualPlots(lr_fit, id = TRUE, col = as.factor( wwines[train_indices,]$outlier), ask = FALSE)
wwines.outlierfree <- wwines[-outliers$.rownames,]
wwines.outlierfree <- wwines[-as.numeric(outliers$.rownames),]
wwines[train_indices,]$outlier<- NULL
#wwines.outlierfree <- wwines[-as.numeric(outliers$.rownames),]
wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-as.numeric(outliers$.rownames),]
wwines.outlierfree <- wwines[-as.numeric(outliers$.rownames),]
wwines.outlierfree[train_indices,]
#wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-as.numeric(outliers$.rownames),]
lr_fit_outlierfree <- glm(quality ~., data =  wwines.outlierfree[train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit_outlierfree)
# odds ratios
exp(cbind(OR = coef(lr_fit_outlierfree), confint(lr_fit_outlierfree)))
train_indices
length(train_indices))
length(train_indices)
for(i in 1:length(train_indices)){
if (train_indices[i] %in% as.numeric(outliers$.rownames)){
train_indices[i] <- NULL
}
}
for(i in 1:length(train_indices)){
if (train_indices[i] %in% as.numeric(outliers$.rownames)){
train_indices[i] <- -train_indices[i]
}
}
train_indices[i] <- -train_indices[i]
train_indices
wwines[train_indices,]$outlier<- NULL
#wwines[train_indices,]$outlier<- NULL
#wwines.outlierfree <- wwines[-as.numeric(outliers$.rownames),]
#wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-as.numeric(outliers$.rownames),]
lr_fit_outlierfree <- glm(quality ~., data =  wwines[train_indices,],
family=binomial(link='logit'))
for(i in 1:length(train_indices)){
if (train_indices[i] %in% as.numeric(outliers$.rownames)){
train_indices[i] <- -train_indices[i]
}
}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(ggplot2)
library(dplyr)
library(reshape2)
library(mlr3learners)
library(pROC)
library(corrplot)
library(gridExtra)
library(GGally)
library(car)
library(broom)
library(ltm)
library(MASS)
wwines <- read.csv("winequality-white.csv", sep=";")
print("White wines")
str(wwines)
wwines$quality <- as.factor(case_when(wwines$quality <= 5 ~ "low",
wwines$quality > 5 ~ "high"))
wwines$quality <- factor(wwines$quality, levels = c("low","high"))
table(wwines$quality)
#compute on all features (without output variable which is at index 12)
cors <- cor(wwines[-12])
corrplot(cors, type = "upper",
tl.col = "black", tl.srt = 45)
h1 <- ggplot(wwines, aes(residual.sugar, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
h2 <- ggplot(wwines, aes(alcohol, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
h3 <- ggplot(wwines, aes(density, color = quality))+
geom_freqpoly(binwidth = 3, size = 1)
grid.arrange(h1,h2,h3, ncol=1)
wwines$density <- NULL
bicorrs <- sapply(wwines[,-11], function(x) round(biserial.cor(x,wwines$quality),2))
data.frame(bicorrs) %>% arrange(abs(bicorrs))
summary(wwines)
# melt the dataset
wwines.m <- melt(wwines, id.var = "quality")
# wrapped boxplots
ggplot(data = wwines.m, aes(x=variable, y=value)) +
geom_boxplot(aes(fill=quality)) +
facet_wrap( ~ variable, scales="free")
set.seed(42)
train_indices<- createDataPartition(wwines$quality,p=0.7,list=FALSE)
lr_fit <- glm(quality ~., data =  wwines[train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit)
# odds ratios
exp(cbind(OR = coef(lr_fit), confint(lr_fit)))
#here we use mlr3 package
#defining our task: classification on wines with quality as response variable and low quality as baseline
task_train = TaskClassif$new(id = "wines",  wwines[train_indices,], target = "quality", positive = "high")
#defining the learner which will perform the training procedure on our model
learner_train = lrn("classif.log_reg", predict_type = "prob")
#defining how we want to perform cross validation (setting number of folds to 5)
cv5 = rsmp("cv", folds = 5)
#we want to tweak the threshold of our classification: we analyze values from 0.3 to 0.6 with step 0.01
thresholds <- seq(0.5,0.8,0.01)
#collecting performances with different thresholds
measures_list <- rep(list(list()), 3)
for (thresh in thresholds) {
res_cv = resample(task_train, learner_train, cv5, store_models = TRUE)
#combined prediction of all individual resampling iterations
prediction <- res_cv$prediction()
prediction$set_threshold(thresh)
#scores are combined as well from all individual resampling iterations
scores <- prediction$score(measures = c(msr("classif.acc"),msr("classif.sensitivity"),msr("classif.specificity")))
coefficients <- (unname(scores))
measures_list <- mapply(append, measures_list, coefficients, SIMPLIFY = FALSE)
}
measures <- data.frame(thresholds,
"accuracy" = unlist(measures_list[[1]]),
"sensitivity" = unlist(measures_list[[2]]),
"specificity" = unlist(measures_list[[3]]))
#finding optimal point: intersection
equivalent <- function(x, y, tol = 0.02) abs(x - y) < tol
intersection_indices <- which(equivalent(measures$sensitivity,measures$specificity))
th <- mean(thresholds[intersection_indices])
melt_measures <- melt(measures, id.vars="thresholds")
ggplot(melt_measures, aes( x=thresholds, y=value, colour=variable, group=variable )) +
geom_line() +
geom_vline(xintercept = th,linetype = "dotted") +
geom_label(aes(x = 0.67, y = 0.5, label = as.character(mean(thresholds[intersection_indices]))))
# define new task for test set
task_test = TaskClassif$new(id = "wines_test",  wwines[-train_indices,], target = "quality", positive = "high")
# train on train task
learner_train$train(task_train)
# predict on test task
pred <- learner_train$predict(task_test)
# set optimal threshold
pred$set_threshold(th)
# performance
cm <- list("confusion" = pred$confusion,
"accuracy" = pred$score(measures = msr("classif.acc")),
"sensitivity"=pred$score(measures = msr("classif.sensitivity")),
"specificity"=pred$score(measures = msr("classif.specificity")))
cm
a <- vif(lr_fit)
#b <- data.frame(a,colnames(wwines)[-12])  %>% mutate(sqrt = sqrt(a)) %>% filter(sqrt > 2)
sqrt(vif(lr_fit))>2 # residual.sugar, density, alcohol
library(leaps)
regfit.fwd=regsubsets(quality~.,data=wwines,method="forward", nvmax=13)
summary.fwd <- summary(regfit.fwd)
plot(summary.fwd$bic,xlab="Number of Variables",ylab="bic")
points(which.min(summary.fwd$bic),summary.fwd$bic[which.min(summary.fwd$bic)],pch=20,col="red")
plot(regfit.fwd,scale="bic")
grid(nx=11,ny=10,col="red",lty = "solid")
abline(h=10, col="yellow", lwd = 10)
text(10.5,9, "Optimal model", col="yellow",cex = 0.8)
wwines.res <- wwines[,c(1,2,4,6,9,10,11)]
lr_fit_res <- glm(quality ~., data =  wwines.res[train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit_res)
# odds ratios
exp(cbind(OR = coef(lr_fit_res), confint(lr_fit_res)))
#unrestricted model performance
unrestr_probs <- predict(lr_fit,  wwines[-train_indices,], type="response")
unrestr_preds <- ifelse(unrestr_probs > th,"high","low")
unrestr_cm <- confusionMatrix(factor(unrestr_preds),
wwines[-train_indices,]$quality,
positive = "high"
)
unrestr_performance <- list(unrestr_cm$overall[1], unrestr_cm$byClass[1], unrestr_cm$byClass[2])
#restricted model performance
restr_probs <- predict(lr_fit_res,  wwines.res[-train_indices,], type="response")
restr_preds <- ifelse(restr_probs > th,"high","low")
restr_cm <- confusionMatrix(factor(restr_preds),                         wwines[-train_indices,]$quality,
positive = "high"
)
restr_performance <- list(restr_cm$overall[1], restr_cm$byClass[1], restr_cm$byClass[2])
data.frame("unrestr_performance" =unlist(unrestr_performance),"restr_performance" = unlist(restr_performance),
"improvement" = unlist(restr_performance)-unlist(unrestr_performance))
#see Cook's distance
influenceIndexPlot(lr_fit, id.n=10)  # 2782, 4481
#using dffits
df_fits<-dffits(lr_fit)
threshold<-(2*(11+1)/sqrt(3429-11-1))
which(abs(df_fits)>threshold) # 2782, 1956
outliers <- c(1956,2782,4481)
wwines[train_indices,]["outlier"] <- ifelse(rownames( wwines[train_indices,]) %in% outliers,0,1)
residualPlots(lr_fit, id = TRUE,  col = as.factor( wwines[train_indices,]$outlier))
#dffits threshold
threshold<-(2*(ncol( wwines[train_indices,])+1)/sqrt(nrow(wwines[train_indices,])-ncol(wwines[train_indices,])-1))
d <- dffits(lr_fit)
#another way to get cook's distance
#cooks distance threshold: https://www.scikit-yb.org/en/latest/api/regressor/influence.html#:~:text=Because%20of%20this%2C%20Cook's%20Distance,that%20is%20above%20that%20threshold.
plot(lr_fit, which = 4, id.n = 3)
outliers <-
augment(lr_fit) %>%
mutate(df = unname(dffits(lr_fit)))%>%
filter(.cooksd > 4/nrow( wwines[train_indices,]) |abs(df)>threshold)
wwines[train_indices,]["outlier"] <- ifelse(rownames(wwines[train_indices,]) %in% outliers$.rownames,0,1)
residualPlots(lr_fit, id = TRUE, col = as.factor( wwines[train_indices,]$outlier), ask = FALSE)
temp_train_indices <- c()
j<-1
for(i in 1:length(train_indices)){
if (!(train_indices[i] %in% as.numeric(outliers$.rownames))){
temp_train_indices[j] <- train_indices[i]
j<-j+1
}
}
temp_train_indices
no_outliers_train_indices <- c()
j<-1
for(i in 1:length(train_indices)){
if (!(train_indices[i] %in% as.numeric(outliers$.rownames))){
no_outliers_train_indices[j] <- train_indices[i]
j<-j+1
}
}
#wwines[train_indices,]$outlier<- NULL
#wwines.outlierfree <- wwines[-as.numeric(outliers$.rownames),]
#wwines[train_indices,]$outlierfree <-  wwines[train_indices,][-as.numeric(outliers$.rownames),]
lr_fit_outlierfree <- glm(quality ~., data =  wwines[no_outliers_train_indices,],
family=binomial(link='logit'))
#removing useless columns
wwines[train_indices,]$outlier<- NULL
#fitting on outlier free data
lr_fit_outlierfree <- glm(quality ~., data =  wwines[no_outliers_train_indices,],
family=binomial(link='logit'))
# coefficients
summary(lr_fit_outlierfree)
# odds ratios
exp(cbind(OR = coef(lr_fit_outlierfree), confint(lr_fit_outlierfree)))
outliers <- data.frame(summary(lr_fit)$coefficient)
no_outliers<- data.frame(summary(lr_fit_outlierfree)$coefficient)
variable<-c("(constant)",colnames(wwines)[-12])
data.frame(variable,outliers$Estimate,no_outliers$Estimate, "difference"=outliers$Estimate-no_outliers$Estimate)
outliers
no_outliers
no_outliers
nrow(outliers)
nrow(no_outliers)
variable
variable<-c("(constant)",colnames(wwines)[-c(1,12)])
variable<-c("(constant)",colnames(wwines)[-c(1,12)])
data.frame(variable,outliers$Estimate,no_outliers$Estimate, "difference"=outliers$Estimate-no_outliers$Estimate)
# outliers free
lr_prob_of <- predict(lr_fit_outlierfree,  wwines[-train_indices,], type="response")
lr_pred_of <- ifelse(lr_prob_of > th,"high","low")
cm_of <- confusionMatrix(as.factor(lr_pred_of),
wwines[-train_indices,]$quality,
positive = "high"
)
out_performance <- list(unrestr_cm$overall[1], unrestr_cm$byClass[1], unrestr_cm$byClass[2])
outfree_performance <- list(cm_of$overall[1], cm_of$byClass[1], cm_of$byClass[2])
data.frame("outliers_performance" = unlist(out_performance),"outliers_free_performance" = unlist(outfree_performance),
"improvement" = unlist(outfree_performance)-unlist(out_performance))
test_roc = roc( wwines[-train_indices,]$quality ~ lr_prob_of, plot = TRUE, print.auc = TRUE)
n <- seq(nrow( wwines[train_indices,]))
set.seed(1)
S1 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(2)
S2 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(3)
S3 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
set.seed(4)
S4 <- sample(n, nrow( wwines[train_indices,]), replace = TRUE)
lr_b <- function(i){
lr_f <- glm(quality ~ fixed.acidity+volatile.acidity+residual.sugar+free.sulfur.dioxide+sulphates+alcohol,
data =  wwines[train_indices,][i, ],family=binomial(link='logit'))
lr_prob <- predict(lr_f, wwines[train_indices,][i,], type="response")
lr_pred <- ifelse(lr_prob > th,"high","low")
cm <- confusionMatrix(
as.factor(lr_pred),
wwines[train_indices,][i,]$quality,
positive = "high"
)
a <- cm$overall[[1]]
return(a)
}
aggregate = (lr_b(S1) +lr_b(S2) + lr_b(S3) + lr_b(S4))/4
round(aggregate,4)
